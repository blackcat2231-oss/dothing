import streamlit as st
import google.generativeai as genai
from PIL import Image
import pandas as pd
import json
from docx import Document
from docx.shared import Pt, RGBColor, Cm
from docx.enum.text import WD_ALIGN_PARAGRAPH
from docx.oxml.ns import qn
import io
import time
import concurrent.futures

# --- 1. ç¶²é åŸºæœ¬è¨­å®š ---
st.set_page_config(page_title="ç¯¤è¡Œå¹¼å…’åœ’è©•é‡ç³»çµ±", layout="wide", page_icon="ğŸŒ±")

st.markdown("""
    <style>
    .main {background-color: #f9f9f9;}
    .stHeader {color: #2c3e50;}
    th {
        white-space: normal !important;
        background-color: #f0f2f6 !important;
    }
    td {text-align: center !important; vertical-align: middle !important;}
    td:last-child {text-align: left !important;}
    .stButton button { width: 100%; font-weight: bold; }
    </style>
    """, unsafe_allow_html=True)

# --- åˆå§‹åŒ– Session ---
if 'raw_records' not in st.session_state: st.session_state['raw_records'] = []
if 'class_df' not in st.session_state: st.session_state['class_df'] = pd.DataFrame()

# --- 2. å´é‚Šæ¬„ ---
with st.sidebar:
    st.header("ğŸŒ± ç¯¤è¡Œå¹¼å…’åœ’")
    st.subheader("è©•é‡ç³»çµ± v3.1 (Gemini 3.0 ç‰ˆ)")
    
    # ç‹€æ…‹å„€è¡¨æ¿
    st.markdown("---")
    count = len(st.session_state['raw_records'])
    st.metric("ğŸ“Š æš«å­˜è³‡æ–™æ•¸", f"{count} ç­†")
    if count > 0:
        st.caption("âœ… è³‡æ–™å·²ä¿å­˜ï¼Œå¯ç”¢ç”Ÿå ±å‘Š")
    st.markdown("---")

    if "GEMINI_API_KEY" in st.secrets:
        genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
        st.success("API é€£ç·šç‹€æ…‹ï¼šğŸŸ¢ ç·šä¸Š")
    else:
        st.error("âŒ API Key æœªè¨­å®š")
        st.stop()
        
    menu = st.radio("åŠŸèƒ½é¸å–®", ["ğŸ“ æ‰¹æ¬¡ä¸Šå‚³èˆ‡è¾¨è­˜", "ğŸ“„ ç”¢ç”Ÿæ•´åˆè©•é‡å ±å‘Š"])

# --- 3. æ ¸å¿ƒåŠŸèƒ½ (è‡ªå‹•ä¿éšªæ©Ÿåˆ¶) ---

def safe_generate_content(prompt, image=None, temperature=0.0):
    """
    é€™æ˜¯ä¸€å€‹å…·å‚™ã€è‡ªå‹•ä¿éšªã€åŠŸèƒ½çš„å‘¼å«å‡½å¼ã€‚
    å„ªå…ˆå˜—è©¦ Gemini 3.0ï¼Œå¦‚æœå¤±æ•— (404/500ç­‰)ï¼Œè‡ªå‹•åˆ‡æ›å›ç©©å®šçš„ Flash æ¨¡å‹ã€‚
    """
    # è¨­å®šé¦–é¸æ¨¡å‹ (Gemini 3.0) èˆ‡ å‚™ç”¨æ¨¡å‹ (Gemini 1.5 Flash)
    primary_model_name = 'gemini-3.0-pro' 
    backup_model_name = 'gemini-1.5-flash'
    
    config = genai.types.GenerationConfig(temperature=temperature)
    inputs = [prompt, image] if image else [prompt]

    # --- ç¬¬ä¸€æ¬¡å˜—è©¦ï¼šä½¿ç”¨ Gemini 3.0 ---
    try:
        model = genai.GenerativeModel(primary_model_name)
        response = model.generate_content(inputs, generation_config=config)
        return response.text
    
    except Exception as e:
        error_msg = str(e)
        # å¦‚æœé‡åˆ° 404 (æ‰¾ä¸åˆ°æ¨¡å‹) æˆ–å…¶ä»–éŒ¯èª¤ï¼Œè½‰ç”¨å‚™æ¡ˆ
        # ä¸é¡¯ç¤ºéŒ¯èª¤çµ¦ä½¿ç”¨è€…ï¼Œç›´æ¥åœ¨å¾Œå°åˆ‡æ›ï¼Œç¢ºä¿ç•™æš¢é«”é©—
        print(f"3.0 æ¨¡å‹å‘¼å«å¤±æ•—: {error_msg}ï¼Œæ­£åœ¨åˆ‡æ›è‡³å‚™ç”¨æ¨¡å‹...")
        
        try:
            # --- ç¬¬äºŒæ¬¡å˜—è©¦ï¼šä½¿ç”¨å‚™ç”¨æ¨¡å‹ (Flash) ---
            model_backup = genai.GenerativeModel(backup_model_name)
            response_backup = model_backup.generate_content(inputs, generation_config=config)
            return response_backup.text
        except Exception as e2:
            # çœŸçš„éƒ½ä¸è¡Œæ‰å›å ±éŒ¯èª¤
            raise Exception(f"æ‰€æœ‰æ¨¡å‹å˜—è©¦çš†å¤±æ•—ã€‚åŸå› : {e2}")

def analyze_single_image(image_file):
    image = Image.open(image_file)
    
    prompt = """
    ä½ æ˜¯ä¸€ä½ç²¾æº–çš„è³‡æ–™è¼¸å…¥å“¡ã€‚é€™æ˜¯ä¸€å¼µå¹¼å…’åœ’è©•é‡è¡¨ã€‚
    
    ã€ä»»å‹™ä¸€ï¼šåˆ¤æ–·å­¸ç¿’å€ã€‘
    çœ‹è¡¨é ­æ–‡å­—ï¼Œåˆ¤æ–·æ˜¯å“ªå€‹å­¸ç¿’å€ (å¦‚:èªæ–‡å€,æ•¸å­¸å€...)ã€‚å­˜å…¥ "area"ã€‚

    ã€ä»»å‹™äºŒï¼šè®€å–æŒ‡æ¨™ã€‘
    è®€å–è¡¨æ ¼ä¸Šæ–¹é‚£ 4 å€‹æ¬„ä½æ¨™é¡Œã€‚

    ã€ä»»å‹™ä¸‰ï¼šåˆ¤æ–·åˆ†æ•¸ (åº§æ¨™å®šä½)ã€‘
    æ¯å€‹æ ¼å­å°æœ‰ "1 2 3 4" æˆ–é¡ä¼¼çš„è©•é‡ä»£è™Ÿã€‚è€å¸«åœˆé¸äº†ä¸€å€‹ã€‚
    è«‹çœ‹åœ“åœˆåœˆåœ¨å“ªè£¡ï¼Œå¦‚æœçœ‹ä¸æ¸…æ¥šï¼Œè«‹æ ¹æ“šä¸Šä¸‹æ–‡æ¨æ–·ï¼š
    - åœˆåœ¨ 1 -> "A" (ä¸»å‹•ç†Ÿç·´)
    - åœˆåœ¨ 2 -> "R" (è¡¨ç¾è‰¯å¥½)
    - åœˆåœ¨ 3 -> "D" (ç™¼å±•ä¸­)
    - åœˆåœ¨ 4 -> "N" (éœ€å”åŠ©)
    
    ã€å‚™è¨»ã€‘
    åˆä½µæ ¼å…§æ‰€æœ‰æ–‡å­—ï¼Œä¿ç•™ç·¨è™Ÿã€‚

    ã€è¼¸å‡º JSONã€‘
    è«‹ç›´æ¥è¼¸å‡ºç´” JSON æ ¼å¼ï¼Œä¸è¦æœ‰ markdown æ¨™è¨˜ã€‚
    {
      "area": "èªæ–‡å€",
      "headers": ["æŒ‡æ¨™1", "æŒ‡æ¨™2", "æŒ‡æ¨™3", "æŒ‡æ¨™4"],
      "students": [
        {"name": "å¹¼å…’ä¸€", "scores": ["A", "R", "A", "R"], "note": "å‚™è¨»..."},
        ...
      ]
    }
    """
    
    # é‡è©¦æ©Ÿåˆ¶ (é‡å°ç¶²è·¯ä¸ç©©)
    max_retries = 3
    last_error = ""
    
    for attempt in range(max_retries):
        try:
            # ä½¿ç”¨æˆ‘å€‘å¯«å¥½çš„å®‰å…¨å‘¼å«å‡½å¼
            text_result = safe_generate_content(prompt, image, temperature=0.0)
            
            # æ¸…æ½” JSON
            if "```json" in text_result:
                text_result = text_result.replace("```json", "").replace("```", "")
            elif "```" in text_result:
                text_result = text_result.replace("```", "")
            
            return {"success": True, "data": json.loads(text_result.strip())}
            
        except Exception as e:
            last_error = str(e)
            if "429" in last_error: # æµé‡é™åˆ¶
                time.sleep(2 * (attempt + 1))
                continue
            else:
                return {"success": False, "error": last_error}
    
    return {"success": False, "error": f"é‡è©¦ {max_retries} æ¬¡å¾Œå¤±æ•—ã€‚åŸå› : {last_error}"}

def process_images_parallel(files):
    results = []
    errors = []
    
    # ç¶­æŒ 2 å€‹åŸ·è¡Œç·’ï¼Œé¿å…å¤ªå¿«è¢«æ“‹
    with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:
        future_to_file = {executor.submit(analyze_single_image, f): f for f in files}
        
        bar = st.progress(0)
        info = st.empty()
        total = len(files)
        done = 0
        
        for future in concurrent.futures.as_completed(future_to_file):
            f = future_to_file[future]
            done += 1
            info.text(f"æ­£åœ¨åˆ†æ ({done}/{total}): {f.name}")
            bar.progress(done / total)
            
            outcome = future.result()
            if outcome["success"]:
                results.append(outcome["data"])
            else:
                errors.append(f"{f.name}: {outcome['error']}")
            
            time.sleep(1) # ç¨å¾®å–˜å£æ°£
            
    info.empty()
    bar.empty()
    return results, errors

def generate_teacher_comments_fast(student_name, records):
    data_text = f"å¹¼å…’ï¼š{student_name}\n"
    for r in records:
        data_text += f"[{r['area']}] å‚™è¨»:{r['note']}\n"
        data_text += f"æˆç¸¾:{[d['score'] for d in r['details']]}\n"

    prompt = f"""
    ä½ æ˜¯ä¸€ä½è³‡æ·±çš„å¹¼å…’åœ’åœ’é•·ã€‚è«‹ç‚º {student_name} å¯«ä¸€ä»½ã€A4ç²¾ç°¡ç‰ˆã€‘è©•èªã€‚
    é™åˆ¶ï¼šç¸½å­—æ•¸ 200 å­—å…§ã€‚èªæ°£æº«æš–ã€å…·é«”ä¸”æ­£å‘ã€‚
    è«‹æ ¹æ“šä¸Šè¿°çš„å­¸ç¿’å€è¡¨ç¾èˆ‡å‚™è¨»ä¾†æ’°å¯«ã€‚
    æ ¼å¼ JSONï¼š
    {{ "observation": "è§€å¯Ÿ...", "suggestion": "å»ºè­°..." }}
    """
    
    try:
        # åŒæ¨£ä½¿ç”¨å®‰å…¨å‘¼å«
        text_result = safe_generate_content(prompt, temperature=0.7)
        text = text_result.replace("```json", "").replace("```", "").strip()
        return json.loads(text)
    except:
        return {"observation": "å­©å­åœ¨å­¸æ ¡è¡¨ç¾ç©©å®šï¼Œè«‹è¦ªå¸«å¤šåŠ æºé€šã€‚", "suggestion": "é™ªä¼´æ˜¯æœ€å¥½çš„ç¦®ç‰©ã€‚"}

def create_word_report(grouped_data):
    doc = Document()
    # è¨­å®šé‚Šç•Œ
    for section in doc.sections:
        section.top_margin = Cm(1.27)
        section.bottom_margin = Cm(1.27)
        section.left_margin = Cm(1.27)
        section.right_margin = Cm(1.27)
    
    # è¨­å®šå­—å‹
    style = doc.styles['Normal']
    style.font.name = 'Microsoft JhengHei'
    style.element.rPr.rFonts.set(qn('w:eastAsia'), 'Microsoft JhengHei')
    style.font.size = Pt(10)
    
    bar = st.progress(0)
    status = st.empty()
    total = len(grouped_data)
    
    for idx, (name, records) in enumerate(grouped_data.items()):
        status.text(f"AI æ­£åœ¨å‹•ç­†æ’°å¯«å ±å‘Š ({idx+1}/{total}): {name} ...")
        bar.progress((idx+1)/total)
        
        if idx > 0: doc.add_page_break()
        
        # æ¨™é¡Œ
        head = doc.add_heading('ç¯¤è¡Œéç‡Ÿåˆ©å¹¼å…’åœ’  å¹¼å…’å­¸ç¿’å€å€‹åˆ¥è©•é‡å ±å‘Š', 0)
        head.alignment = WD_ALIGN_PARAGRAPH.CENTER
        head.style.font.size = Pt(16)
        
        p = doc.add_paragraph()
        p.alignment = WD_ALIGN_PARAGRAPH.CENTER
        run = p.add_run(f"å¹¼å…’å§“åï¼š{name}     æ—¥æœŸï¼š2026å¹´___æœˆ___æ—¥")
        run.bold = True
        run.font.size = Pt(12)
        
        table = doc.add_table(rows=1, cols=2)
        table.style = 'Table Grid'
        
        hdr = table.rows[0].cells
        hdr[0].text = "å„å€å­¸ç¿’æŒ‡æ¨™å…§å®¹"
        hdr[1].text = "çµæœ"
        table.columns[0].width = Cm(14)
        table.columns[1].width = Cm(3)
        
        for r in records:
            row = table.add_row().cells
            row[0].merge(row[1])
            p_area = row[0].paragraphs[0]
            run_area = p_area.add_run(f"â–  {r['area']}")
            run_area.bold = True
            run_area.font.color.rgb = RGBColor(0, 51, 102)
            
            for item in r['details']:
                row_item = table.add_row().cells
                row_item[0].text = item['idx']
                row_item[0].paragraphs[0].paragraph_format.left_indent = Cm(0.5)
                row_item[1].text = item['score']
                row_item[1].paragraphs[0].alignment = WD_ALIGN_PARAGRAPH.CENTER
        
        doc.add_paragraph("")
        # å‘¼å« AI å¯«è©•èª
        comments = generate_teacher_comments_fast(name, records)
        
        doc.add_paragraph("ã€è€å¸«çš„è§€å¯Ÿã€‘").runs[0].bold = True
        doc.add_paragraph(comments['observation'])
        doc.add_paragraph("ã€å±…å®¶äº’å‹•å°æ’‡æ­¥ã€‘").runs[0].bold = True
        doc.add_paragraph(comments['suggestion'])
        
        footer = doc.add_paragraph("è©•é‡ä»£è™Ÿï¼šA(ä¸»å‹•ç†Ÿç·´) R(è¡¨ç¾è‰¯å¥½) D(ç™¼å±•ä¸­) N(éœ€å”åŠ©)")
        footer.alignment = WD_ALIGN_PARAGRAPH.CENTER
        footer.runs[0].font.color.rgb = RGBColor(128,128,128)
        footer.runs[0].font.size = Pt(9)

    bar.empty()
    status.empty()
    
    bio = io.BytesIO()
    doc.save(bio)
    return bio

# --- 4. ä¸»é é¢ ---

if menu == "ğŸ“ æ‰¹æ¬¡ä¸Šå‚³èˆ‡è¾¨è­˜":
    st.title("ğŸ“ æ‰¹æ¬¡è™•ç† (v3.1 é›™å¼•æ“ä¿éšªç‰ˆ)")
    st.info("ğŸ’¡ ç³»çµ±é è¨­å„ªå…ˆä½¿ç”¨ Gemini 3.0ã€‚è‹¥ç¶²è·¯å¿™ç¢Œï¼Œå°‡è‡ªå‹•åˆ‡æ›è‡³ 1.5 Flash ç¢ºä¿ä¸ä¸­æ–·ã€‚")
    
    files = st.file_uploader("é¸æ“‡ç…§ç‰‡ (å…¨é¸)", type=['jpg','png','jpeg'], accept_multiple_files=True)
    
    if files and st.button("ğŸš€ é–‹å§‹åˆ†æ"):
        results, errors = process_images_parallel(files)
        
        # 1. è™•ç†æˆåŠŸçš„éƒ¨åˆ†
        if results:
            all_data = []
            raw_records = []
            for res in results:
                area = res.get("area","æœªçŸ¥")
                headers = res.get("headers", ["I1","I2","I3","I4"])
                for s in res.get("students", []):
                    row = {"å¹¼å…’å§“å":s.get("name"), "å­¸ç¿’å€":area}
                    scores = s.get("scores", [])
                    details = []
                    for i, sc in enumerate(scores):
                        if i < 4: 
                            h_name = headers[i] if i < len(headers) else f"æŒ‡æ¨™{i+1}"
                            row[h_name] = sc
                            details.append({"idx": h_name, "score": sc})
                    row["å‚™è¨»"] = s.get("note")
                    all_data.append(row)
                    raw_records.append({
                        "name": s.get("name"),
                        "area": area,
                        "details": details,
                        "note": s.get("note")
                    })
            
            # è¿½åŠ è³‡æ–™
            if 'raw_records' not in st.session_state: st.session_state['raw_records'] = []
            st.session_state['raw_records'].extend(raw_records)
            
            # æ›´æ–°é¡¯ç¤ºè¡¨æ ¼
            if 'class_df' not in st.session_state: st.session_state['class_df'] = pd.DataFrame()
            new_df = pd.DataFrame(all_data)
            st.session_state['class_df'] = pd.concat([st.session_state['class_df'], new_df], ignore_index=True)
            
            st.success(f"âœ… æˆåŠŸè™•ç† {len(results)} å¼µç…§ç‰‡ï¼")
        
        # 2. è™•ç†å¤±æ•—çš„éƒ¨åˆ†
        if errors:
            st.error(f"âš ï¸ æœ‰ {len(errors)} å¼µç…§ç‰‡è™•ç†å¤±æ•—ï¼ŒåŸå› å¦‚ä¸‹ï¼š")
            for err in errors:
                st.code(err)
                if "429" in err:
                    st.warning("ğŸ‘‰ æç¤ºï¼šæµé‡è¼ƒå¤§ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚")

    if not st.session_state['class_df'].empty:
        st.dataframe(st.session_state['class_df'])

elif menu == "ğŸ“„ ç”¢ç”Ÿæ•´åˆè©•é‡å ±å‘Š":
    st.title("ğŸ“„ å ±å‘Šç”Ÿæˆ")
    
    if st.session_state['raw_records']:
        grouped = {}
        for r in st.session_state['raw_records']:
            name = r['name']
            if name not in grouped: grouped[name] = []
            grouped[name].append(r)
        
        st.write(f"ğŸ“š è³‡æ–™åº«å°±ç·’ï¼šå…± {len(grouped)} ä½å¹¼å…’è³‡æ–™ã€‚")

        if st.button("âœ¨ é»æ“Šé€™è£¡ç”¢ç”Ÿ Word æª”"):
            with st.spinner("AI åœ’é•·æ­£åœ¨å‹•ç­†å¯«è©•èª (æ™ºæ…§é›™å¼•æ“é‹ç®—ä¸­)..."):
                doc_file = create_word_report(grouped)
                st.session_state['generated_doc'] = doc_file.getvalue()
                st.success("å ±å‘Šç”¢ç”Ÿå®Œç•¢ï¼")
        
        if 'generated_doc' in st.session_state:
            st.download_button(
                label="ğŸ“¥ é»æˆ‘ä¸‹è¼‰ Word è©•é‡å ±å‘Š",
                data=st.session_state['generated_doc'],
                file_name="ç¯¤è¡Œå¹¼å…’åœ’_è©•é‡å ±å‘Š_Final.docx",
                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
            )
            
    else:
        st.warning("âš ï¸ æš«å­˜å€æ˜¯ç©ºçš„ï¼è«‹å…ˆå›ä¸Šä¸€é ä¸Šå‚³ä¸¦åˆ†æç…§ç‰‡ã€‚")
