import streamlit as st
import google.generativeai as genai
from PIL import Image
import pandas as pd
import json
from docx import Document
from docx.shared import Pt, RGBColor
from docx.enum.text import WD_ALIGN_PARAGRAPH
from docx.enum.table import WD_TABLE_ALIGNMENT
from docx.oxml.ns import qn
import io
import time

# --- 1. ç¶²é åŸºæœ¬è¨­å®š ---
st.set_page_config(page_title="ç¯¤è¡Œå¹¼å…’åœ’è©•é‡ç³»çµ±", layout="wide", page_icon="ğŸŒ±")

st.markdown("""
    <style>
    .main {background-color: #f9f9f9;}
    .stHeader {color: #2c3e50;}
    th {
        white-space: normal !important;
        min-width: 120px;
        vertical-align: top !important;
        background-color: #f0f2f6 !important;
    }
    td {text-align: center !important; vertical-align: middle !important;}
    td:last-child {text-align: left !important;}
    </style>
    """, unsafe_allow_html=True)

# --- 2. å´é‚Šæ¬„èˆ‡ API è¨­å®š ---
with st.sidebar:
    st.image("https://cdn-icons-png.flaticon.com/512/2231/2231649.png", width=100)
    st.title("ğŸŒ± ç¯¤è¡Œå¹¼å…’åœ’")
    st.subheader("è©•é‡ç³»çµ± v1.8 (å…¨èƒ½æ•´åˆç‰ˆ)")
    
    if "GEMINI_API_KEY" in st.secrets:
        genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
        st.success("API é€£ç·šç‹€æ…‹ï¼šğŸŸ¢ ç·šä¸Š")
    else:
        st.error("API Key æœªè¨­å®š")
        st.stop()
        
    st.markdown("---")
    menu = st.radio("åŠŸèƒ½é¸å–®", ["ğŸ“ æ‰¹æ¬¡ä¸Šå‚³èˆ‡è¾¨è­˜", "ğŸ“„ ç”¢ç”Ÿæ•´åˆè©•é‡å ±å‘Š"])

# --- 3. æ ¸å¿ƒåŠŸèƒ½å‡½å¼ ---

def get_gemini_model():
    """å°‹æ‰¾æœ€å¼·æ¨¡å‹"""
    model_list = []
    try:
        for m in genai.list_models():
            if 'generateContent' in m.supported_generation_methods:
                model_list.append(m.name)
        priority_keywords = ['gemini-3', 'gemini-2.5', 'pro', 'flash']
        for keyword in priority_keywords:
            for name in model_list:
                if keyword in name and ('1.5' in name if keyword == 'flash' else True):
                    return genai.GenerativeModel(name), name
    except:
        pass
    return genai.GenerativeModel('gemini-1.5-flash'), 'fallback-flash'

def analyze_image(image):
    """AI è¾¨è­˜æ ¸å¿ƒï¼šåŠ å…¥å­¸ç¿’å€åˆ¤æ–·"""
    model, model_name = get_gemini_model()
    
    prompt = """
    ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„è³‡æ–™è¼¸å…¥å“¡ã€‚è«‹åˆ†æé€™å¼µå¹¼å…’åœ’è©•é‡è¡¨ã€‚
    
    ã€ä»»å‹™ä¸€ï¼šåˆ¤æ–·å­¸ç¿’å€ã€‘
    è«‹é–±è®€è¡¨é ­ï¼Œåˆ¤æ–·é€™å¼µè¡¨å±¬æ–¼å“ªå€‹å­¸ç¿’å€ï¼Ÿ(ä¾‹å¦‚ï¼šèªæ–‡å€ã€æ•¸å­¸å€ã€ç¾å‹å€ã€ç©æœ¨å€ã€é«”èƒ½å€...)ã€‚
    è«‹å°‡çµæœæ”¾å…¥ "area" æ¬„ä½ã€‚

    ã€ä»»å‹™äºŒï¼šè®€å–è¡¨é ­æŒ‡æ¨™ã€‘
    è«‹è®€å–è¡¨æ ¼æœ€ä¸Šæ–¹ã€ä½æ–¼ã€Œå¹¼å…’å§“åã€èˆ‡ã€Œå‚™è¨»ã€ä¸­é–“çš„é‚£ 4 å€‹æ¬„ä½æ¨™é¡Œæ–‡å­—ã€‚
    
    ã€ä»»å‹™ä¸‰ï¼šè®€å–å¹¼å…’è³‡æ–™ã€‘
    è«‹ä¾åºè®€å–æ¯ä¸€åˆ—å¹¼å…’çš„è³‡æ–™ã€‚
    
    **é—œæ–¼ã€Œå‚™è¨»ã€çš„æŒ‡ç¤ºï¼š**
    1. å°‡æ ¼å­å…§æ‰€æœ‰æ–‡å­—åˆä½µã€‚
    2. ä¿ç•™æ›è¡Œæˆ–ç·¨è™Ÿ (â‘ , 1.)ã€‚

    **é—œæ–¼ã€Œåˆ†æ•¸ã€çš„åˆ¤æ–·ï¼š**
    - åœˆé¸ 1 -> "A"
    - åœˆé¸ 2 -> "R"
    - åœˆé¸ 3 -> "D"
    - åœˆé¸ 4 -> "N"

    ã€è¼¸å‡ºæ ¼å¼ã€‘
    å›å‚³ JSONï¼š
    {
      "area": "èªæ–‡å€",
      "headers": ["æŒ‡æ¨™1æ–‡å­—", "æŒ‡æ¨™2æ–‡å­—", "æŒ‡æ¨™3æ–‡å­—", "æŒ‡æ¨™4æ–‡å­—"],
      "students": [
        {"name": "å¹¼å…’ä¸€", "scores": ["A", "R", "A", "R"], "note": "å‚™è¨»å…§å®¹..."},
        ...
      ]
    }
    """
    
    config = genai.types.GenerationConfig(temperature=0.0, response_mime_type="application/json")
    try:
        response = model.generate_content([prompt, image], generation_config=config)
        return json.loads(response.text)
    except:
        return None

def generate_teacher_comments(student_name, records):
    """
    AI å¯«æ‰‹æ ¸å¿ƒï¼š
    å°‡è©²ä½å¹¼å…’çš„æ‰€æœ‰å€åŸŸè³‡æ–™æ‰“åŒ…ï¼Œè«‹ AI å¯«å‡ºåƒç¯„ä¾‹ä¸€æ¨£çš„ã€Œç¶œåˆè§€å¯Ÿã€èˆ‡ã€Œå±…å®¶å»ºè­°ã€ã€‚
    """
    model, _ = get_gemini_model()
    
    # å°‡è³‡æ–™è½‰ç‚ºæ–‡å­—æè¿°çµ¦ AI çœ‹
    data_summary = f"å¹¼å…’å§“åï¼š{student_name}\n"
    for r in records:
        data_summary += f"--- {r['area']} ---\n"
        data_summary += f"æŒ‡æ¨™èˆ‡æˆç¸¾ï¼š{r['details']}\n" # details åŒ…å«æŒ‡æ¨™åç¨±èˆ‡åˆ†æ•¸
        data_summary += f"è€å¸«åŸå§‹å‚™è¨»ï¼š{r['note']}\n"
    
    prompt = f"""
    ä½ æ˜¯ä¸€ä½è³‡æ·±çš„å¹¼å…’åœ’åœ’é•·èˆ‡æ•™è‚²å°ˆå®¶ã€‚è«‹æ ¹æ“šä»¥ä¸‹é€™ä½å¹¼å…’åœ¨ä¸åŒå­¸ç¿’å€çš„è©•é‡æ•¸æ“šèˆ‡è€å¸«å‚™è¨»ï¼Œæ’°å¯«ä¸€ä»½çµ¦å®¶é•·çš„ç¶œåˆè©•èªã€‚
    
    ã€å¹¼å…’è³‡æ–™ã€‘
    {data_summary}
    
    ã€æ’°å¯«ç›®æ¨™ã€‘
    è«‹æ¨¡ä»¿ä»¥ä¸‹é¢¨æ ¼ï¼Œæ’°å¯«å…©å€‹æ®µè½ï¼š
    
    1. **ã€è€å¸«çš„è§€å¯Ÿã€‘**ï¼š
       - ç¶œåˆæ‰€æœ‰å€åŸŸçš„è¡¨ç¾ï¼Œæ‰¾å‡ºå­©å­çš„äº®é»ï¼ˆå“ªè£¡è¡¨ç¾å¥½/Aç´šï¼‰ã€‚
       - æº«æŸ”åœ°æŒ‡å‡ºéœ€è¦å”åŠ©çš„åœ°æ–¹ï¼ˆå“ªè£¡æ˜¯Dæˆ–Nï¼‰ï¼Œä¸¦å°‡å…¶æè¿°ç‚ºã€Œç™¼å±•ä¸­çš„çè²´éšæ®µã€ã€‚
       - èªæ°£è¦æº«æš–ã€æ­£å‘ã€å°ˆæ¥­ã€‚
       - å¦‚æœåŸå§‹å‚™è¨»æœ‰å…·é«”äº‹ä»¶ï¼ˆå¦‚ã€Œæé¾ç‹åœ‹ã€ï¼‰ï¼Œè«‹å‹™å¿…å¯«é€²å»ï¼Œè®“æ•…äº‹æ›´ç”Ÿå‹•ã€‚
       
    2. **ã€å±…å®¶äº’å‹•å°æ’‡æ­¥ã€‘**ï¼š
       - é‡å°å­©å­è¼ƒå¼±çš„é …ç›®ï¼ˆR/D/Nï¼‰ï¼Œçµ¦å®¶é•·å…·é«”ã€ç°¡å–®ã€å¯åœ¨å®¶é€²è¡Œçš„éŠæˆ²æˆ–äº’å‹•å»ºè­°ã€‚
       - å¦‚æœå­©å­éƒ½å¾ˆå¥½ï¼Œå‰‡å»ºè­°å¦‚ä½•å»¶ä¼¸æŒ‘æˆ°ã€‚
    
    ã€è¼¸å‡ºæ ¼å¼ã€‘
    è«‹ç›´æ¥å›å‚³ JSONï¼Œä¸è¦ markdownï¼š
    {{
        "observation": "é€™è£¡å¯«è€å¸«çš„è§€å¯Ÿæ®µè½...",
        "suggestion": "é€™è£¡å¯«å±…å®¶äº’å‹•å°æ’‡æ­¥..."
    }}
    """
    
    config = genai.types.GenerationConfig(temperature=0.7, response_mime_type="application/json") # ç¨å¾®æé«˜æº«åº¦è®“æ–‡ç­†æ›´å¥½
    try:
        response = model.generate_content(prompt, generation_config=config)
        return json.loads(response.text)
    except:
        return {"observation": "AI æ’°å¯«ä¸­...", "suggestion": "å»ºè­°è¦ªå¸«ä¿æŒå¯†åˆ‡è¯ç¹«ã€‚"}

def create_integrated_word(grouped_data):
    """ç”¢ç”Ÿæ•´åˆç‰ˆ Word å ±å‘Š"""
    doc = Document()
    style = doc.styles['Normal']
    style.font.name = 'Microsoft JhengHei'
    style.element.rPr.rFonts.set(qn('w:eastAsia'), 'Microsoft JhengHei')
    
    # é€²åº¦é¡¯ç¤º
    progress_text = "æ­£åœ¨æ’°å¯«å ±å‘Š..."
    my_bar = st.progress(0, text=progress_text)
    total_students = len(grouped_data)
    
    for idx, (name, records) in enumerate(grouped_data.items()):
        # æ›´æ–°é€²åº¦
        my_bar.progress((idx + 1) / total_students, text=f"æ­£åœ¨ç‚º {name} æ’°å¯«è©•èª ({idx+1}/{total_students})...")
        
        if idx > 0: doc.add_page_break()
        
        # 1. æ¨™é¡Œ
        head = doc.add_heading('ç¯¤è¡Œéç‡Ÿåˆ©å¹¼å…’åœ’', 0)
        head.alignment = WD_ALIGN_PARAGRAPH.CENTER
        sub = doc.add_paragraph('å¹¼å…’å­¸ç¿’å€å€‹åˆ¥è©•é‡å ±å‘Š')
        sub.alignment = WD_ALIGN_PARAGRAPH.CENTER
        sub.runs[0].bold = True
        sub.runs[0].font.size = Pt(14)
        
        doc.add_paragraph(f"å¹¼å…’å§“åï¼š{name} \t\t\t æ—¥æœŸï¼š2026å¹´___æœˆ___æ—¥")
        
        # 2. å‘¼å« AI é€²è¡Œç¶œåˆå¯«ä½œ (é€™æ˜¯æœ€èŠ±æ™‚é–“çš„ä¸€æ­¥)
        ai_comments = generate_teacher_comments(name, records)
        
        # 3. å»ºç«‹å¤§è¡¨æ ¼ (åŒ…å«å„å€)
        doc.add_paragraph("â–  å„å€å­¸ç¿’æŒ‡æ¨™æ˜ç´°").runs[0].bold = True
        
        table = doc.add_table(rows=1, cols=2)
        table.style = 'Table Grid'
        hdr = table.rows[0].cells
        hdr[0].text = "å­¸ç¿’æŒ‡æ¨™"
        hdr[1].text = "è©•é‡çµæœ"
        
        # å¡«å…¥å„å€è³‡æ–™
        for record in records:
            # åŠ å…¥å€åŸŸæ¨™é¡Œåˆ— (ä¾‹å¦‚ï¼šèªæ–‡å€)
            row_area = table.add_row().cells
            row_area[0].merge(row_area[1])
            run = row_area[0].paragraphs[0].add_run(f"ã€{record['area']}ã€‘")
            run.bold = True
            run.font.color.rgb = RGBColor(0, 102, 204) # è—è‰²æ¨™é¡Œ
            row_area[0].paragraphs[0].alignment = WD_ALIGN_PARAGRAPH.LEFT
            
            # åŠ å…¥è©²å€çš„æŒ‡æ¨™
            # record['details'] æ˜¯ä¸€å€‹ list: [{"idx": "èƒ½é–±è®€...", "score": "A"}, ...]
            for item in record['details']:
                row = table.add_row().cells
                row[0].text = item['idx']
                row[1].text = item['score']
                row[1].paragraphs[0].alignment = WD_ALIGN_PARAGRAPH.CENTER

        doc.add_paragraph("")
        
        # 4. å¯«å…¥ AI ç”Ÿæˆçš„è©•èª
        doc.add_heading('è¦ªå¸«äº¤æµèˆ‡å»ºè­°', level=2)
        
        obs_title = doc.add_paragraph("ã€è€å¸«çš„è§€å¯Ÿã€‘")
        obs_title.runs[0].bold = True
        doc.add_paragraph(ai_comments['observation'])
        
        sug_title = doc.add_paragraph("ã€å±…å®¶äº’å‹•å°æ’‡æ­¥ã€‘")
        sug_title.runs[0].bold = True
        doc.add_paragraph(ai_comments['suggestion'])
        
        doc.add_paragraph("")
        
        # 5. é å°¾
        footer = doc.add_paragraph("è©•é‡ä»£è™Ÿèªªæ˜ï¼š A(ä¸»å‹•ç†Ÿç·´)  R(è¡¨ç¾è‰¯å¥½)  D(ç™¼å±•ä¸­/éœ€ç¤ºç¯„)  N(æœªè§€å¯Ÿ/éœ€å”åŠ©)")
        footer.alignment = WD_ALIGN_PARAGRAPH.CENTER
        footer.style = 'Quote'

    my_bar.empty()
    
    bio = io.BytesIO()
    doc.save(bio)
    return bio

def color_grade(val):
    if val == 'A': return 'background-color: #d4edda; color: green; font-weight: bold;'
    if val == 'R': return 'background-color: #fff3cd; color: #856404; font-weight: bold;'
    if val == 'D': return 'background-color: #ffeeba; color: orange; font-weight: bold;'
    if val == 'N': return 'background-color: #f8d7da; color: red; font-weight: bold;'
    return ''

# --- 4. ä¸»é é¢é‚è¼¯ ---

if menu == "ğŸ“ æ‰¹æ¬¡ä¸Šå‚³èˆ‡è¾¨è­˜":
    st.title("ğŸ“ è©•é‡è¡¨æ‰¹æ¬¡è™•ç† (v1.8)")
    st.info("ğŸ’¡ è«‹ä¸Šå‚³ä¸åŒå­¸ç¿’å€çš„ç…§ç‰‡ï¼ˆä¾‹å¦‚ï¼šèªæ–‡å€ç…§ç‰‡+æ•¸å­¸å€ç…§ç‰‡ï¼‰ï¼Œç³»çµ±æœƒè‡ªå‹•è­˜åˆ¥ä¸¦åˆ†é¡ã€‚")
    
    uploaded_files = st.file_uploader("è«‹é¸æ“‡è©•é‡è¡¨ç…§ç‰‡", type=['jpg', 'png', 'jpeg'], accept_multiple_files=True)
    
    if uploaded_files and st.button("ğŸš€ é–‹å§‹åˆ†æä¸¦æ­¸æª”"):
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        all_data = [] # ç”¨ä¾†å­˜ DataFrame
        raw_records = [] # ç”¨ä¾†å­˜åŸå§‹çµæ§‹è³‡æ–™ (çµ¦ Word ç”Ÿæˆç”¨)

        for i, file in enumerate(uploaded_files):
            status_text.text(f"æ­£åœ¨åˆ†æç¬¬ {i+1} å¼µç…§ç‰‡...")
            image = Image.open(file)
            result = analyze_image(image)
            
            if result:
                area = result.get("area", "æœªçŸ¥å€åŸŸ")
                headers = result.get("headers", ["æŒ‡æ¨™1","æŒ‡æ¨™2","æŒ‡æ¨™3","æŒ‡æ¨™4"])[:4]
                
                for s in result.get("students", []):
                    # 1. å­˜å…¥ DataFrame ç”¨çš„æ‰å¹³è³‡æ–™
                    row = {"å¹¼å…’å§“å": s.get("name"), "å­¸ç¿’å€": area}
                    scores = s.get("scores", [])
                    for idx, score in enumerate(scores):
                        if idx < 4: row[headers[idx]] = score
                    row["å‚™è¨»"] = s.get("note")
                    all_data.append(row)
                    
                    # 2. å­˜å…¥çµæ§‹åŒ–è³‡æ–™ (çµ¦ AI å¯«ä½œç”¨)
                    details = []
                    for idx, score in enumerate(scores):
                        if idx < 4:
                            details.append({"idx": headers[idx], "score": score})
                            
                    raw_records.append({
                        "name": s.get("name"),
                        "area": area,
                        "details": details,
                        "note": s.get("note")
                    })

            progress_bar.progress((i + 1) / len(uploaded_files))
            time.sleep(1)

        if all_data:
            st.session_state['class_df'] = pd.DataFrame(all_data)
            st.session_state['raw_records'] = raw_records # é€™æ˜¯ç”Ÿæˆ Word çš„é—œéµ
            st.success(f"å·²æˆåŠŸè®€å– {len(uploaded_files)} å¼µè¡¨å–®ï¼Œå…± {len(all_data)} ç­†ç´€éŒ„ï¼")

    if 'class_df' in st.session_state:
        st.divider()
        st.subheader("ğŸ“Š è³‡æ–™é è¦½")
        st.dataframe(st.session_state['class_df'], use_container_width=True)

elif menu == "ğŸ“„ ç”¢ç”Ÿæ•´åˆè©•é‡å ±å‘Š":
    st.title("ğŸ“„ æ•´åˆè©•é‡å ±å‘Šç”Ÿæˆä¸­å¿ƒ")
    
    if 'raw_records' in st.session_state and len(st.session_state['raw_records']) > 0:
        records = st.session_state['raw_records']
        
        # ä¾å§“åé€²è¡Œæ­¸æˆ¶ (Grouping)
        grouped_data = {}
        for r in records:
            name = r['name']
            if name not in grouped_data:
                grouped_data[name] = []
            grouped_data[name].append(r)
            
        st.success(f"ç›®å‰è³‡æ–™åº«ä¸­å…±æœ‰ {len(grouped_data)} ä½å¹¼å…’çš„å®Œæ•´å­¸ç¿’æ­·ç¨‹ã€‚")
        st.info("é»æ“Šä¸‹æ–¹æŒ‰éˆ•å¾Œï¼ŒAI å°‡æœƒç‚ºæ¯ä¸€ä½å¹¼å…’ã€Œé–±è®€ã€æ‰€æœ‰å€åŸŸçš„æˆç¸¾ï¼Œä¸¦æ’°å¯«å®¢è£½åŒ–çš„è§€å¯Ÿå ±å‘Šã€‚é€™å¯èƒ½éœ€è¦å¹¾åˆ†é˜ï¼Œè«‹è€å¿ƒç­‰å€™ã€‚")
        
        if st.button("âœ¨ å•Ÿå‹• AI å¯«ä½œä¸¦ä¸‹è¼‰å ±å‘Š"):
            doc_file = create_integrated_word(grouped_data)
            
            st.download_button(
                label="ğŸ“¥ ä¸‹è¼‰å…¨ç­æ•´åˆå ±å‘Š (Word)",
                data=doc_file,
                file_name="ç¯¤è¡Œå¹¼å…’åœ’_å…¨ç­æ•´åˆè©•é‡å ±å‘Š.docx",
                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
            )
            st.balloons()
            
    else:
        st.warning("âš ï¸ å°šç„¡è³‡æ–™ï¼Œè«‹å…ˆè‡³ã€Œæ‰¹æ¬¡ä¸Šå‚³ã€é é¢åˆ†æç…§ç‰‡ã€‚")
